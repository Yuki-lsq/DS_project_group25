{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.metrics import r2_score\n",
    "import psutil\n",
    "import time\n",
    "import random "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7q/hh0pfzcs5hj7w_hgxcd3vr1m0000gn/T/ipykernel_4600/1980125538.py:1: DtypeWarning: Columns (1169,1171) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('philippines_model.csv')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('philippines_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['emotional_valid_count', 'emotional_valid_sum', 'emotional_avg', 'physical_valid_count', 'physical_valid_sum', 'physical_avg','sexual_valid_count','sexual_valid_sum', 'sexual_avg', 'overall_valid_count', 'overall_valid_sum', 'unique_id', 'caseid']\n",
    "data_cleaned = data.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35961, 615)\n"
     ]
    }
   ],
   "source": [
    "# Delete one value dominated columns\n",
    "threshold = 0.8\n",
    "\n",
    "columns_to_drop = [col for col in data_cleaned.columns if data_cleaned[col].value_counts(normalize=True).max() >= threshold]\n",
    "\n",
    "data_cleaned_1 = data_cleaned.drop(columns=columns_to_drop)\n",
    "\n",
    "print(data_cleaned_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35961, 407)\n"
     ]
    }
   ],
   "source": [
    "# Delete highly correlated columns\n",
    "y = 'overall_avg'\n",
    "year = 'v007'\n",
    "\n",
    "data_numeric = data_cleaned_1.drop(columns=[y]).select_dtypes(include=['int64', 'float64'])\n",
    "corr_matrix = data_numeric.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "\n",
    "threshold = 0.9\n",
    "columns_to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "\n",
    "data_cleaned_2 = data_cleaned_1.drop(columns=columns_to_drop)\n",
    "data_cleaned_2[year] = data_cleaned_1[year]\n",
    "data_cleaned_2[\"overall_avg\"] = data_cleaned_2[y]\n",
    "\n",
    "print(data_cleaned_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.011765095801433128\n",
      "Root Mean Squared Error: 0.10846702633258241\n",
      "Mean Absolute Error: 0.03846933972079262\n",
      "R-squared: 0.8472037033441899\n",
      "Train time: 2.31 seconds\n",
      "Memory used during training: 129.77 MB\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "\n",
    "X = data_cleaned_2.drop(columns=['overall_avg'])  # 输入特征\n",
    "y = data_cleaned_2['overall_avg']  # 目标变量\n",
    "\n",
    "\n",
    "# threshold for catgorical variables\n",
    "unique_threshold = 18  \n",
    "\n",
    "for col in X.select_dtypes(include=['int']).columns:\n",
    "    if X[col].nunique() < unique_threshold:\n",
    "        X[col] = X[col].astype('category')\n",
    "\n",
    "for col in X.select_dtypes(include=['object']).columns:\n",
    "    X[col] = X[col].astype('category')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "process = psutil.Process()\n",
    "start_mem = process.memory_info().rss / 1024 ** 2 \n",
    "\n",
    "\n",
    "model = xgb.XGBRegressor(missing=np.nan, enable_categorical=True)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "train_time = time.time() - start_time\n",
    "end_mem = process.memory_info().rss / 1024 ** 2  # 转换为 MB\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# result\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'R-squared: {r2}')\n",
    "print(f'Train time: {train_time:.2f} seconds')\n",
    "print(f'Memory used during training: {end_mem - start_mem:.2f} MB')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 7 rounds\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's l2: 0.0102848\n",
      "Mean Squared Error: 0.010284768197090196\n",
      "Root Mean Squared Error: 0.10141384618034263\n",
      "Mean Absolute Error: 0.03556501736053339\n",
      "R-squared: 0.8664290950960714\n",
      "Train time: 1.05 seconds\n",
      "Memory used during training: 325.25 MB\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "\n",
    "X = data_cleaned_2.drop(columns=['overall_avg'])  # 输入特征\n",
    "y = data_cleaned_2['overall_avg']  # 目标变量\n",
    "\n",
    "\n",
    "unique_threshold = 18  \n",
    "\n",
    "for col in X.select_dtypes(include=['int']).columns:\n",
    "    if X[col].nunique() < unique_threshold:\n",
    "        X[col] = X[col].astype('category')\n",
    "\n",
    "for col in X.select_dtypes(include=['object']).columns:\n",
    "    X[col] = X[col].astype('category')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "categorical_features = [\n",
    "    i for i, col in enumerate(X_train.columns) if X_train[col].dtype.name == 'category']\n",
    "\n",
    "\n",
    "process = psutil.Process()\n",
    "start_mem = process.memory_info().rss / 1024 ** 2  \n",
    "\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mse',\n",
    "    'max_bin': 400,\n",
    "    'num_leaves': 30,\n",
    "    'learning_rate': 0.1,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train, categorical_feature=categorical_features)\n",
    "valid_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=100, \n",
    "    valid_sets=[valid_data],\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=7)]  \n",
    ")\n",
    "\n",
    "train_time = time.time() - start_time\n",
    "end_mem = process.memory_info().rss / 1024 ** 2 \n",
    "\n",
    "y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "\n",
    "# result\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'R-squared: {r2}')\n",
    "print(f'Train time: {train_time:.2f} seconds')\n",
    "print(f'Memory used during training: {end_mem - start_mem:.2f} MB')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.010017138115420798\n",
      "Root Mean Squared Error: 0.10008565389415607\n",
      "Mean Absolute Error: 0.03551231746109955\n",
      "R-squared: 0.8699048751528554\n",
      "Train time: 29.91 seconds\n",
      "Memory used during training: 314.58 MB\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "\n",
    "X = data_cleaned_2.drop(columns=['overall_avg'])  # 输入特征\n",
    "y = data_cleaned_2['overall_avg']  # 目标变量\n",
    "\n",
    "for col in X.select_dtypes(include=['category', 'object']).columns:\n",
    "    X[col] = X[col].astype(str).fillna('NaN')\n",
    "\n",
    "unique_threshold = 18 \n",
    "\n",
    "for col in X.select_dtypes(include=['int']).columns:\n",
    "    if X[col].nunique() < unique_threshold:\n",
    "        X[col] = X[col].astype('category')\n",
    "\n",
    "for col in X.select_dtypes(include=['object']).columns:\n",
    "    X[col] = X[col].astype('category')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "categorical_features = X_train.select_dtypes(include=['category']).columns.tolist()\n",
    "\n",
    "start_time = time.time()\n",
    "process = psutil.Process()\n",
    "start_mem = process.memory_info().rss / 1024 ** 2  # 转换为 MB\n",
    "\n",
    "model = CatBoostRegressor(iterations=500, learning_rate=0.1, depth=6, loss_function='RMSE', verbose=False)\n",
    "\n",
    "model.fit(X_train, y_train, cat_features=categorical_features)\n",
    "\n",
    "\n",
    "train_time = time.time() - start_time\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# result\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'R-squared: {r2}')\n",
    "print(f'Train time: {train_time:.2f} seconds')\n",
    "print(f'Memory used during training: {end_mem - start_mem:.2f} MB')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
